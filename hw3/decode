#!/usr/bin/env python
import argparse
import copy
import sys
import math
import models
import heapq
import random
import itertools
import operator

from collections import namedtuple

def contains_sublist(lst, sublst):
    n = len(sublst)
    return any((sublst == lst[i:i+n]) for i in xrange(len(lst)-n+1))

parser = argparse.ArgumentParser(description='Simple phrase based decoder.')
parser.add_argument('-i', '--input', dest='input', default='data/input', help='File containing sentences to translate (default=data/input)')
parser.add_argument('-t', '--translation-model', dest='tm', default='data/tm', help='File containing translation model (default=data/tm)')
parser.add_argument('-s', '--stack-size', dest='s', default=1, type=int, help='Maximum stack size (default=1)')
parser.add_argument('-n', '--num_sentences', dest='num_sents', default=sys.maxint, type=int, help='Number of sentences to decode (default=no limit)')
parser.add_argument('-l', '--language-model', dest='lm', default='data/lm', help='File containing ARPA-format language model (default=data/lm)')
parser.add_argument('-v', '--verbose', dest='verbose', action='store_true', default=False,  help='Verbose mode (default=off)')
opts = parser.parse_args()

tm = models.TM(opts.tm, sys.maxint)
lm = models.LM(opts.lm)
sys.stderr.write('Decoding %s...\n' % (opts.input,))
input_sents = [tuple(line.strip().split()) for line in open(opts.input).readlines()[:opts.num_sents]]

hypothesis = namedtuple('hypothesis', 'logprob, lm_state, predecessor, phrase, start, end')
sample_hypothesis = namedtuple('sample_hypothesis', 'lm_state, phrase, start, end')

def retranslate_prob(possible_translations, lm_state, next_word_logprob):
    rp = [0] * len(possible_translations)
    for k in range(len(rp)):
        t = possible_translations[k]
        rp[k] += t.logprob
        for word in t.english.split():
            (lm_state, word_logprob) = lm.score(lm_state, word)
            rp[k] += word_logprob

        rp[k] += next_word_logprob

    Z = [math.exp(float(x)) for x in rp]
    return [float(x)/sum(Z) for x in Z]

def reorder_prob(possible_positions, original_pos, hypotheses):
    rp = [0] * len(possible_positions)
    if original_pos == 0:
        original_lm_state = lm.begin()
    else:
        original_lm_state = hypotheses[original_pos - 1].lm_state
    p1 = hypotheses[original_pos].phrase

    for k in range(len(rp)):
        pos = possible_positions[k]
        if pos == 0:
            swap_lm_state = lm.begin()
        else:
            swap_lm_state = hypotheses[pos - 1].lm_state
        p2 = hypotheses[pos].phrase

        lm_state = original_lm_state
        for word in p2.english.split():
            (lm_state, word_logprob) = lm.score(lm_state, word)
            rp[k] += word_logprob
        (_, next_word_logprob) = lm.score(lm_state, hypotheses[original_pos + 1].phrase.english.split()[0])
        rp[k] += next_word_logprob

        lm_state = swap_lm_state
        for word in p1.english.split():
            (lm_state, word_logprob) = lm.score(lm_state, word)
            rp[k] += word_logprob
        (_, next_word_logprob) = lm.score(lm_state, hypotheses[pos + 1].phrase.english.split()[0])
        rp[k] += next_word_logprob

    Z = [math.exp(float(x)) for x in rp]
    return [float(x)/sum(Z) for x in Z]

def sample(hypotheses, phrase_dict):
    translations = dict()
    sample_hypotheses = [] 

    for h in hypotheses:
        sample_hypotheses.append(sample_hypothesis(h.lm_state, h.phrase, h.start, h.end))

    for i in range(50000):
        for j in range(len(sample_hypotheses)):
            # Retranslate
            sh = sample_hypotheses[j]
            possible_translations = phrase_dict[(sh.start, sh.end)]
            if j == 0:
                lm_state = lm.begin()
            else:
                lm_state = sample_hypotheses[j - 1].lm_state
            if j + 1 == len(sample_hypotheses):
                next_word_logprob = lm.end(lm_state)
            else:
                (_, next_word_logprob) = lm.score(lm_state, sample_hypotheses[j+1].phrase.english.split()[0])

            normalized = retranslate_prob(possible_translations, lm_state, next_word_logprob)
            print normalized
            prob = random.random()
            for k in range(len(normalized)):
                prob -= normalized[k]
                if prob < 0.0:
                    break

            # Rebuild the sample hypotheses
            if j == 0:
                lm_state = lm.begin()
            else:
                lm_state = sample_hypotheses[j - 1].lm_state

            for word in possible_translations[k].english.split():
                (lm_state, _) = lm.score(lm_state, word)
            sample_hypotheses[j] = sample_hypothesis(lm_state, possible_translations[k], sh.start, sh.end)

            # Reorder
            if j == len(sample_hypotheses) - 1:
                continue
            sh = sample_hypotheses[j]
            possible_positions = []
            for k in range(-2, 3):
                if j + k < 0 or j + k >= len(sample_hypotheses) - 1:
                    continue
                possible_positions.append(j + k)

            normalized = reorder_prob(possible_positions, j, sample_hypotheses)
            print normalized
            prob = random.random()
            for k in range(len(normalized)):
                prob -= normalized[k]
                if prob < 0.0:
                    break

            # Rebuild the sample hypotheses
            swh = sample_hypotheses[possible_positions[k]]
            if j == 0:
                lm_state = lm.begin()
            else:
                lm_state = sample_hypotheses[j - 1].lm_state

            for word in swh.phrase.english.split():
                (lm_state, _) = lm.score(lm_state, word)
            sample_hypotheses[j] = sample_hypothesis(lm_state, swh.phrase, swh.start, swh.end)


            if possible_positions[k] == 0:
                lm_state = lm.begin()
            else:
                lm_state = sample_hypotheses[possible_positions[k] - 1].lm_state

            for word in sh.phrase.english.split():
                (lm_state, _) = lm.score(lm_state, word)
            sample_hypotheses[possible_positions[k]] = sample_hypothesis(lm_state, sh.phrase, sh.start, sh.end)

        sentence = ' '.join([x.phrase.english for x in sample_hypotheses])
        coverage_alignment = [(x.start, x.end) for x in sample_hypotheses]
        if not sentence in translations:
            translations[sentence] = 1
        else:
            translations[sentence] += 1

    print max(translations.iteritems(), key=operator.itemgetter(1))[0]


for f in input_sents:
    # The following code implements a DP monotone decoding
    # algorithm (one that doesn't permute the target phrases).
    # Hence all hypotheses in stacks[i] represent translations of 
    # the first i words of the input sentence.
    # HINT: Generalize this so that stacks[i] contains translations
    # of any i words (remember to keep track of which words those
    # are, and to estimate future costs)
    initial_hypothesis = hypothesis(0.0, lm.begin(), None, None, -1, -1)

    stacks = [{} for _ in f] + [{}]
    stacks[0][lm.begin()] = initial_hypothesis

    phrase_dict = dict()

    for i, stack in enumerate(stacks[:-1]):
        if i+2 < len(stacks):
            for h in heapq.nlargest(opts.s, stacks[i].itervalues(), key=lambda h: h.logprob):
                for k in range(i+1,len(f)+1):
                    if f[i:k] in tm:
                        for j in range(k+1,len(f)+1):
                            if f[k:j] in tm:
                                new_stacks = []
                                for phrase in tm[f[k:j]]:
                                    logprob = h.logprob + phrase.logprob
                                    lm_state = h.lm_state
                                    for word in phrase.english.split():
                                        (lm_state, word_logprob) = lm.score(lm_state, word)
                                        logprob += word_logprob
                                    logprob += lm.end(lm_state) if j == len(f) else 0.0
                                    new_hypothesis = hypothesis(logprob, lm_state, h, phrase, k, j)
                                    new_stacks.append(new_hypothesis)

                                for hi in new_stacks:
                                    for phrase in tm[f[i:k]]:
                                        logprob = hi.logprob + phrase.logprob
                                        lm_state = hi.lm_state
                                        for word in phrase.english.split():
                                            (lm_state, word_logprob) = lm.score(lm_state, word)
                                            logprob += word_logprob
                                        logprob += lm.end(lm_state) if k == len(f) else 0.0
                                        new_hypothesis = hypothesis(logprob, lm_state, hi, phrase, i, k)

                                        if lm_state not in stacks[j] or stacks[j][lm_state].logprob < logprob: # second case is recombination
                                            stacks[j][lm_state] = new_hypothesis 

        # extend the top s hypotheses in the current stack
        for h in heapq.nlargest(opts.s, stacks[i].itervalues(), key=lambda h: h.logprob): # prune
            for j in xrange(i+1,len(f)+1):
                if f[i:j] in tm:
                    for phrase in tm[f[i:j]]:
                        if not (i, j) in phrase_dict:
                            phrase_dict[(i, j)] = [phrase]
                        else:
                            phrase_dict[(i, j)].append(phrase)
                        logprob = h.logprob + phrase.logprob
                        lm_state = h.lm_state
                        for word in phrase.english.split():
                            (lm_state, word_logprob) = lm.score(lm_state, word)
                            logprob += word_logprob
                        logprob += lm.end(lm_state) if j == len(f) else 0.0
                        new_hypothesis = hypothesis(logprob, lm_state, h, phrase, i, j)
                        if lm_state not in stacks[j] or stacks[j][lm_state].logprob < logprob: # second case is recombination
                            stacks[j][lm_state] = new_hypothesis 

    # find best translation by looking at the best scoring hypothesis
    # on the last stack
    winner = max(stacks[-1].itervalues(), key=lambda h: h.logprob)

    def extract_hypotheses_recursive(h):
        if h.predecessor is None:
            return []
        else:
            hs = extract_hypotheses_recursive(h.predecessor)
            hs.append(h)
            return hs

    hypotheses = extract_hypotheses_recursive(winner)
    sample(hypotheses, phrase_dict)

    if opts.verbose:
        def extract_tm_logprob(h):
            return 0.0 if h.predecessor is None else h.phrase.logprob + extract_tm_logprob(h.predecessor)
        tm_logprob = extract_tm_logprob(winner)
        sys.stderr.write('LM = %f, TM = %f, Total = %f\n' % 
            (winner.logprob - tm_logprob, tm_logprob, winner.logprob))
