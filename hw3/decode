#!/usr/bin/env python
import argparse
import copy
import sys
import math
import models
import heapq
import random
import itertools
import operator

from collections import namedtuple

# Three little utility functions:
def coverage(sequence):
    # Generate a coverage for a sequence of indexes #
    # You can do things like:
    #   c1 | c2 to "add" coverages
    #   c1 & c2 will return 0 if c1 and c2 do NOT overlap
    #   c1 & c2 will be != 0 if c1 and c2 DO overlap
    return reduce(lambda x,y: x|y, map(lambda i: long(1) << i, sequence), 0)

def coverage2str(c, n, on='o', off='.'):
    # Generate a length-n string representation of coverage c #
    return '' if n==0 else (on if c&1==1 else off) + coverage2str(c>>1, n-1, on, off)

def logadd(x,y):
    # Addition in logspace: if x=log(a) and y=log(b), return log(a+b) #
    return x + math.log(1 + math.exp(y-x)) if y < x else y + math.log(1 + math.exp(x-y))

def contains_sublist(lst, sublst):
    n = len(sublst)
    return any((sublst == lst[i:i+n]) for i in xrange(len(lst)-n+1))

parser = argparse.ArgumentParser(description='Simple phrase based decoder.')
parser.add_argument('-i', '--input', dest='input', default='data/input', help='File containing sentences to translate (default=data/input)')
parser.add_argument('-t', '--translation-model', dest='tm', default='data/tm', help='File containing translation model (default=data/tm)')
parser.add_argument('-s', '--stack-size', dest='s', default=1, type=int, help='Maximum stack size (default=1)')
parser.add_argument('-n', '--num_sentences', dest='num_sents', default=sys.maxint, type=int, help='Number of sentences to decode (default=no limit)')
parser.add_argument('-l', '--language-model', dest='lm', default='data/lm', help='File containing ARPA-format language model (default=data/lm)')
parser.add_argument('-v', '--verbose', dest='verbose', action='store_true', default=False,  help='Verbose mode (default=off)')
opts = parser.parse_args()

tm = models.TM(opts.tm, sys.maxint)
lm = models.LM(opts.lm)
sys.stderr.write('Decoding %s...\n' % (opts.input,))
input_sents = [tuple(line.strip().split()) for line in open(opts.input).readlines()[:opts.num_sents]]

def score_sentence_pair(f, e):
    sent_logprob = 0.0
    # compute p(e) under the LM
    lm_state = lm.begin()
    lm_logprob = 0.0
    for word in e + ("</s>",):
        (lm_state, word_logprob) = lm.score(lm_state, word)
        lm_logprob += word_logprob
    sent_logprob += lm_logprob

    # alignments[i] is a list of all the phrases in f that could have
    # generated phrases starting at position i in e
    alignments = [[] for _ in e]
    for fi in xrange(len(f)):
        for fj in xrange(fi+1,len(f)+1):
            if f[fi:fj] in tm:
                for phrase in tm[f[fi:fj]]:
                    ephrase = tuple(phrase.english.split())
                    for ei in xrange(len(e)+1-len(ephrase)):
                        ej = ei+len(ephrase)
                        if ephrase == e[ei:ej]:
                            alignments[ei].append((ej, phrase.logprob, fi, fj))

    # Compute sum of probability of all possible alignments by dynamic programming.
    # To do this, recursively compute the sum over all possible alignments for each
    # each pair of English prefix (indexed by ei) and French coverage (indexed by 
    # coverage v), working upwards from the base case (ei=0, v=0) [i.e. forward chaining]. 
    # The final sum is the one obtained for the pair (ei=len(e), v=range(len(f))
    chart = [{} for _ in e] + [{}]
    chart[0][0] = 0.0
    for ei, sums in enumerate(chart[:-1]):
        for v in sums:
            for ej, logprob, fi, fj in alignments[ei]:
                if coverage(range(fi,fj)) & v == 0:
                    new_v = coverage(range(fi,fj)) | v
                    if new_v in chart[ej]:
                        chart[ej][new_v] = logadd(chart[ej][new_v], sums[v]+logprob)
                    else:
                        chart[ej][new_v] = sums[v]+logprob
    goal = coverage(range(len(f)))
    if goal in chart[len(e)]:
        sent_logprob += chart[len(e)][goal]
    return sent_logprob

hypothesis = namedtuple('hypothesis', 'logprob, lm_state, predecessor, phrase, start, end')
sample_hypothesis = namedtuple('sample_hypothesis', 'lm_state, phrase, start, end')

for f in input_sents:
    # The following code implements a DP monotone decoding
    # algorithm (one that doesn't permute the target phrases).
    # Hence all hypotheses in stacks[i] represent translations of 
    # the first i words of the input sentence.
    # HINT: Generalize this so that stacks[i] contains translations
    # of any i words (remember to keep track of which words those
    # are, and to estimate future costs)
    initial_hypothesis = hypothesis(0.0, lm.begin(), None, None, -1, -1)

    stacks = [{} for _ in f] + [{}]
    stacks[0][lm.begin()] = initial_hypothesis

    phrase_dict = dict()

    for i, stack in enumerate(stacks[:-1]):
        if i+2 < len(stacks):
            for h in heapq.nlargest(opts.s, stacks[i].itervalues(), key=lambda h: h.logprob):
                for k in range(i+1,len(f)+1):
                    if f[i:k] in tm:
                        for j in range(k+1,len(f)+1):
                            if f[k:j] in tm:
                                for l in range(j+1,len(f)+1):
                                    if f[j:l] in tm:
                                        phrases = [(i,k),(k,j),(j,l)]
                                        phrase_permutations = itertools.permutations(phrases, 3)
                                        for p in phrase_permutations:
                                            new_stacks = []
                                            for phrase in tm[f[p[0][0]:p[0][1]]]:
                                                logprob = h.logprob + phrase.logprob
                                                lm_state = h.lm_state
                                                for word in phrase.english.split():
                                                    (lm_state, word_logprob) = lm.score(lm_state, word)
                                                    logprob += word_logprob
                                                logprob += lm.end(lm_state) if p[0][1] == len(f) else 0.0
                                                new_hypothesis = hypothesis(logprob, lm_state, h, phrase, p[0][0], p[0][1])
                                                new_stacks.append(new_hypothesis)

                                            new_stacks2 = []
                                            for hi in new_stacks:
                                                for phrase in tm[f[p[1][0]:p[1][1]]]:
                                                    logprob = hi.logprob + phrase.logprob
                                                    lm_state = hi.lm_state
                                                    for word in phrase.english.split():
                                                        (lm_state, word_logprob) = lm.score(lm_state, word)
                                                        logprob += word_logprob
                                                    logprob += lm.end(lm_state) if p[1][1] == len(f) else 0.0
                                                    new_hypothesis = hypothesis(logprob, lm_state, hi, phrase, p[1][0], p[1][1])
                                                    new_stacks2.append(new_hypothesis)

                                            for hj in new_stacks2:
                                                for phrase in tm[f[p[2][0]:p[2][1]]]:
                                                    logprob = hj.logprob + phrase.logprob
                                                    lm_state = hj.lm_state
                                                    for word in phrase.english.split():
                                                        (lm_state, word_logprob) = lm.score(lm_state, word)
                                                        logprob += word_logprob
                                                    logprob += lm.end(lm_state) if p[2][1] == len(f) else 0.0
                                                    new_hypothesis = hypothesis(logprob, lm_state, hj, phrase, p[2][0], p[2][1])

                                                    if lm_state not in stacks[l] or stacks[l][lm_state].logprob < logprob: # second case is recombination
                                                        stacks[l][lm_state] = new_hypothesis 

        # extend the top s hypotheses in the current stack
        for h in heapq.nlargest(opts.s, stacks[i].itervalues(), key=lambda h: h.logprob): # prune
            for j in xrange(i+1,len(f)+1):
                if f[i:j] in tm:
                    for phrase in tm[f[i:j]]:
                        if not (i, j) in phrase_dict:
                            phrase_dict[(i, j)] = [phrase]
                        else:
                            phrase_dict[(i, j)].append(phrase)
                        logprob = h.logprob + phrase.logprob
                        lm_state = h.lm_state
                        for word in phrase.english.split():
                            (lm_state, word_logprob) = lm.score(lm_state, word)
                            logprob += word_logprob
                        logprob += lm.end(lm_state) if j == len(f) else 0.0
                        new_hypothesis = hypothesis(logprob, lm_state, h, phrase, i, j)
                        if lm_state not in stacks[j] or stacks[j][lm_state].logprob < logprob: # second case is recombination
                            stacks[j][lm_state] = new_hypothesis 

    # find best translation by looking at the best scoring hypothesis
    # on the last stack
    winner = max(stacks[-1].itervalues(), key=lambda h: h.logprob)
    def extract_english_recursive(h):
        return '' if h.predecessor is None else '%s%s ' % (extract_english_recursive(h.predecessor), h.phrase.english)

    def extract_hypotheses_recursive(h):
        if h.predecessor is None:
            return []
        else:
            hs = extract_hypotheses_recursive(h.predecessor)
            hs.append(h)
            return hs

    hypotheses = extract_hypotheses_recursive(winner)
    K = 5
    best = -1e9
    best_sentence = extract_hypotheses_recursive(winner)
    rerank = heapq.nlargest(K, stacks[-1].itervalues(), key=lambda h: h.logprob)
    for i in range(len(rerank)):
        rerank_hs = extract_hypotheses_recursive(rerank[i])
        sentence = tuple([x.phrase.english for x in rerank_hs])
        score = score_sentence_pair(f, sentence)
        if score > best:
            best = score
            best_sentence = sentence

    print ' '.join(list(best_sentence))
    #sample(hypotheses, phrase_dict, winner.logprob)

    if opts.verbose:
        def extract_tm_logprob(h):
            return 0.0 if h.predecessor is None else h.phrase.logprob + extract_tm_logprob(h.predecessor)
        tm_logprob = extract_tm_logprob(winner)
        sys.stderr.write('LM = %f, TM = %f, Total = %f\n' % 
            (winner.logprob - tm_logprob, tm_logprob, winner.logprob))
